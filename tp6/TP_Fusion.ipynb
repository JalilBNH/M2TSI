{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62be8ac-887a-4049-8bda-efaaba5a1d8e",
   "metadata": {},
   "source": [
    "**TP : La Fusion Multimodale**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9fe6b9-270c-4651-8ba0-37dee41cd0ac",
   "metadata": {},
   "source": [
    "Lors de ce TP, nous allons étudier la fuson multimodale au niveau de la décision  et par la suite au niveau des caractéristiques (early fusion)\n",
    "\n",
    "Pour cela, vous avez à disposition une partie de la base de données AffectNet. AffectNet est une base qui contient presque 300.000 images réparties sur 8 classes (émotions).\n",
    "Pou ce TP, nous utiliserons que 4 classes : anger, happu, neutral et surprise. \n",
    "chaque classe contient 1000 images.\n",
    "\n",
    "Vous avez également une base de données de cartes de profondeur. Ces cartes representent les images d'AffectNet. Elles ont été synthétisées grâce à Depth Anything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486ebea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d88f42d-b12d-43c7-a3b5-812746ed65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliothéques\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import os \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c0cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d47fcdc0-3bd3-460c-8dd0-fd22547b0298",
   "metadata": {},
   "source": [
    "***Créez une fonction appelée data_visualization(classes, data) qui visualise la distribution des données dans un dataset en traçant un graphique en barres. Cette fonction doit prendre comme arguments une liste de classes (correspondant aux catégories) et une liste contenant le nombre d'images par catégorie***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e9c49d3-c36f-4beb-897f-6ecb2dea3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visualization(data_path, classes):\n",
    "    data_per_class = np.empty(len(classes))\n",
    "    print(classes)\n",
    "    for i, classe in enumerate(classes):\n",
    "        data_per_class[i] = len(os.path.join('../datasets/tp6/data/depth', classe))\n",
    "    print(data_per_class)\n",
    "    sns.histplot(data_per_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8abc5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visualization(data_path):\n",
    "\n",
    "    classes = os.listdir(data_path)\n",
    "    data_per_class = np.empty(len(classes))\n",
    "\n",
    "    for i, cls in enumerate(classes) :\n",
    "        data_per_class[i] = len(os.listdir(os.path.join(data_path, cls)))\n",
    "\n",
    "    print(data_per_class)\n",
    "    plt.bar(classes, height=data_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ce22347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000. 1000. 1000. 1000.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_visualization(data_path='../datasets/tp6/data/depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee67f5b0-f1b7-4e3a-a18d-b1e4607da207",
   "metadata": {},
   "source": [
    "**Écrivez une fonction load_data() qui :**\n",
    "\n",
    "**1. Charge un dataset à partir d'un chemins de fichiers différents, en parcourant les sous-dossiers correspondant aux différentes classes d’émotions.**\n",
    "\n",
    "**2. Charge les images de chaque classe, les redimensionne à une taille de 100x100, et les stocke dans une liste.**\n",
    "\n",
    "**3. Encode les étiquettes des classes avec un encodeur LabelEncoder, puis effectue une conversion en encodage one-hot.**\n",
    "\n",
    "**4. Visualise la distribution du nombre d'images par catégorie à l'aide d'une fonction data_visualization()**\n",
    "\n",
    "**Retourne deux valeurs : les images et les étiquettes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad7a17-ca1b-4e9e-9e26-bf02884698c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "\n",
    "      \n",
    "      print(\"\\nTotal number of uploaded data: \", data.shape[0],\n",
    "          \", with data shape\", (data.shape[1],data.shape[2]))\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b631ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/tp6/data/depth'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b66db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d32644f-a740-476a-807c-b2883d228def",
   "metadata": {},
   "source": [
    "data_rgb, labels_rgb = load_data(path_rgb)\n",
    "\n",
    "data_depth, labels_depth = load_data(path_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45e657-74a5-4ac4-af97-aeb08da31064",
   "metadata": {},
   "source": [
    "**Écrivez un code pour diviser un dataset en plusieurs sous-ensembles en suivant les étapes suivantes :**\n",
    "\n",
    "**1. Divisez le dataset en deux sous-ensembles : un pour l'entraînement (70% des données) et un autre pour les tests (30% des données).**\n",
    "\n",
    "**2. Prenez le sous-ensemble de test et divisez-le à nouveau en deux sous-ensembles égaux : un pour la validation (50%) et un autre pour les tests (50%).**\n",
    "\n",
    "**3. Affichez les formes (dimensions) des jeux de données résultants : [X_train_rgb, X_valid_rgb, X_test_rgb, y_train_rgb, y_valid_rgb, y_test_rgb] et [X_train_d, X_valid_d, X_test_d, y_train_d, y_valid_d, y_test_d].**\n",
    "\n",
    "**Attention ! mettez shuffle = False afin d'avoir le même autre d'apparition des RGB et Depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7407e-c9c8-4b18-8959-a602abf4d941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1978e86-9613-4a23-8eca-85ad3b20bca7",
   "metadata": {},
   "source": [
    "**Créez un dictionnaire mapping qui mappe les labels des émotions à leurs noms respectifs. Par exemple, 0 correspond à 'anger', 1 à 'contempt', etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472c981-0c73-4163-9348-22e8a3620262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ecc85a9-1725-4c7e-bcf8-6f1e19d40fd9",
   "metadata": {},
   "source": [
    "**Préparer l'augmentation des données : Utilisez ImageDataGenerator pour créer un objet d'augmentation des données qui applique certaines transformations aux images d'entraînement. Les transformations doivent inclure :**\n",
    "\n",
    "**- Une rotation aléatoire jusqu'à 15 degrés.**\n",
    "\n",
    "**- Un zoom aléatoire jusqu'à 15%.**\n",
    "\n",
    "**- Un ajustement de la luminosité dans une plage de (0.6, 1.2).**\n",
    "\n",
    "**- Une transformation en cisaillement jusqu'à 15%.**\n",
    "\n",
    "**- Un retournement horizontal aléatoire.**\n",
    "\n",
    "**- Le mode de remplissage doit être défini à \"nearest\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745935b-a2c7-4cdf-848e-3ccef84ec284",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf04c24-77e2-430d-9ae3-06ef2d22c13b",
   "metadata": {},
   "source": [
    "**Affichez 9 exemples d'images augmentées aléatoirement à partir de votre ensemble d'entraînement en utilisant trainAug.flow() et affichez chaque image avec son label d'émotion associé.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887391c-d8e8-459f-8f24-9c7d600e8abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f158131-ad15-433d-9651-4e85568a510a",
   "metadata": {},
   "source": [
    "**late Fusion : Écrivez une fonction build_model() qui construit un model avec CNN(EfficientNet / VGG16 / VGG19) pré-entrainé sur ImageNet. N'oubliez pas de mettre classes=None. \n",
    "Ce modèle sera connecter à un Dense de 256, un BatchNormalization et un Dropout de 0.2. \n",
    "Duppliquez cette architecture en prenant soit le même CNNN ou bien un autre.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d709d3b-6284-42f0-8902-053ca5485b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    EffNet = tf.keras.applications.efficientnet_v2.EfficientNetV2S()           \n",
    "    input1 = Input(shape=input_shape)\n",
    "    x = EffNet (input1)\n",
    "    model_1 = Model(input1, x) \n",
    "    \n",
    "    VGG = tf.keras.applications.VGG16()\n",
    "    input2 = Input(shape=input_shape)\n",
    "    y = VGG(input2)\n",
    "    model_2 = Model(input2, y)  \n",
    "    \n",
    "     \n",
    "    z = tf.keras.layers.Average(name='average_layer')([model_1.output, model_2.output])\n",
    "    model = Model(inputs=[model_2.input, model_1.input], outputs = z)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353275c6-9363-4b3e-8940-44a3898d9ca2",
   "metadata": {},
   "source": [
    "**Implémentez des callbacks pour surveiller les performances de votre modèle pendant l'entraînement. Vous devez inclure les éléments suivants :**\n",
    "\n",
    "**- Checkpointing du modèle : Utilisez ModelCheckpoint pour enregistrer le modèle lorsque l'accuracy sur le jeu de validation (val_accuracy) est maximale. Le fichier du modèle doit être sauvegardé uniquement si c'est la meilleure performance atteinte jusqu'à présent.**\n",
    "\n",
    "**- Early Stopping : Utilisez EarlyStopping pour arrêter l'entraînement si l'accuracy sur le jeu de validation ne s'améliore pas après 5 époques.**\n",
    "\n",
    "**- Réduction du taux d'apprentissage : Utilisez ReduceLROnPlateau pour réduire le taux d'apprentissage de moitié si l'accuracy sur le jeu de validation ne s'améliore pas après 5 époques consécutives. Assurez-vous que le taux d'apprentissage ne tombe pas en dessous de 1e-6.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c3285e-ac40-4c52-ad5b-31b77d734b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \".hdf5\"\n",
    "\n",
    "checkpoint = \n",
    "earlystopping = \n",
    "rlrop = \n",
    "\n",
    "callbacks = [checkpoint, earlystopping, rlrop]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bbf9a-0616-4b02-a2bf-7d6774802228",
   "metadata": {},
   "source": [
    "**Écrivez un code pour entraîner un modèle de classification d’émotions en utilisant une augmentation des données, des callbacks, et une validation croisée. Votre tâche est de :**\n",
    "\n",
    "**- Configurer l'entraînement du modèle : Utilisez la fonction fit() pour entraîner le modèle sur les deux données augmentées.**\n",
    "\n",
    "**- Inclure la validation : Utilisez les deux jeux de validation pour valider les performances du modèle à chaque époque.**\n",
    "\n",
    "**- Spécifier les callbacks : Passez la liste des callbacks.**\n",
    "\n",
    "**- Définir les paramètres d'entraînement : Le nombre d’époques (EPOCHS) et la taille des mini-lots (batch_size) doivent être définis. Utilisez steps_per_epoch pour calculer le nombre de lots nécessaires à chaque époque.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64216d76-32fa-4cde-83de-d5a5a1455b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "batch_size = 32\n",
    "\n",
    "print(f\"[INFO] training network for {EPOCHS} epochs...\\n\")\n",
    "hist = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addcf433-77c7-4ff7-9477-9bd181bdfdc5",
   "metadata": {},
   "source": [
    "**Faites la prédiction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037e7ad-7627-4cf8-afca-8aec8a3b3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b36c5-e804-4fc7-b8b5-6ac519210721",
   "metadata": {},
   "source": [
    "**Affichez la loss et l'accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b13d4-b191-4dc3-846b-9d7667dc8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the values of previous plot\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "fig.add_subplot(121)\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('Training & Validation Accuracy Plot')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "fig.add_subplot(122)\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('Training & Validation Loss Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cddd55-d2cb-4375-87d0-1f4d03ce6573",
   "metadata": {},
   "source": [
    "**Ajuster le code ci-dessous afin qu'il affiche 5 images aléatoires RGB avec leur depth ainsi que la classe predite et réelle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6dd5e6-18ce-456c-90ed-a98d2343dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.choice(len(X_test), 5)\n",
    "\n",
    "fig, axes = plt.subplots(len(samples), 2, figsize=(18, 13))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=-0.2)\n",
    "\n",
    "for i, (prediction, image, label) in enumerate(zip(predictions, X_test[samples], y_test[samples])):\n",
    "\n",
    "    axes[i, 0].imshow(np.squeeze(image/255.))\n",
    "    axes[i, 0].get_xaxis().set_visible(False)\n",
    "    axes[i, 0].get_yaxis().set_visible(False)\n",
    "    axes[i, 0].text(1., -3, f'Actual Emotion: [{mapping[np.argmax(label)]}]', weight='bold')\n",
    "\n",
    "    axes[i, 1].bar(np.arange(len(prediction)), prediction)\n",
    "    axes[i, 1].set_xticks(np.arange(len(prediction)))\n",
    "    axes[i, 1].set_title(f\"Model's Prediction: [{mapping[np.argmax(prediction)]}]\", weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7344bebf-dfb8-44a8-9e48-d8aa22c7eb77",
   "metadata": {},
   "source": [
    "**Implémentez une fonction show_confusion_matrix() qui :**\n",
    "\n",
    "**- Fait des prédictions : Utilise le modèle pour prédire les catégories des images du jeu de test, qui n'a pas été vu par le modèle.**\n",
    "\n",
    "**- Crée une matrice de confusion : Compare les prédictions avec les vraies étiquettes en utilisant une matrice de confusion. Les prédictions et les vraies étiquettes doivent être mappées aux noms des classes d'émotions.**\n",
    "\n",
    "**- Affiche la matrice de confusion : Tracez la matrice de confusion sous forme de carte thermique (heatmap) annotée avec les vraies étiquettes sur l'axe des lignes et les étiquettes prédites sur l'axe des colonnes.**\n",
    "\n",
    "**- Calcule la précision finale : Calculez et affichez la précision du modèle sur le jeu de test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa306f-7ccf-4036-9a61-d3c820a35e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(X_test_rgb, y_test_rgb):\n",
    "\n",
    "    data = {'y_Actual':    actual_labels,\n",
    "            'y_Predicted': pred_labels}\n",
    "\n",
    "    confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "\n",
    "    print(f\"Final accuracy: \")\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(10,8)) \n",
    "    sn.heatmap(confusion_matrix, annot = True, ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a7dd4-e474-4b18-b852-99bc3bdd1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion_matrix(X_test_rgb, y_test_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d78d9d-bf97-48ad-a63a-250f6314ab80",
   "metadata": {},
   "source": [
    "**Créez deux fonctions : une fonction qui va créer un modèle pour traiter les images RGB et un autre qui va créer un modèle que pour les images depth. Evaluez les 3 modèles entre eux. Est ce que la fusion multimodale apporte plus de précision ?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3b6f2-3038-4fb1-9a9d-d169f494ce42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
